---
calendar: ml
post_year: 2019
post_day: 19
title: 'Reinforcement learnign explaos '
---
Recently, machine learning research have increasingly been focused on general learning algorithms where the same algorithm can perform a huge variety of tasks. The ultimate goal by reinforcement learning researchers is to create machines that can learn to solve any general task, just like humans! Yesterday, you were introduced to Reinforcement Learning, and today we're going to take a brief look at some of the coolest projects and greatest breakthroughs in the field of self-learning machines.

Two of the leading AI companies, DeepMind and OpenAI, have been focusing on learning machines to play increasingly complex games. By having the same algorithm learn to play multiple games from scratch, without being explicitly programmed to play one particular game, they get one step closer to general artificial intelligence (or singuarity, which may well be the end of all of humanity).

This is [what DeepMind did to Atari games in 2013](https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning). They presented a Deep Learning model that learnt, from scratch, to play seven different Atari games, surpassing humans in a matter of hours. The really groundbreaking thing about this achievement was that machines didn't need any information other than the game frames to learn. They were essentially able to learn playing the games just by looking at the screen (like humans!) while smashing random buttons (like humans playing Tekken!) – until their random actions eventually started paying off. The machines would then recognize which actions paid off and which didn’t, and after trying again and again, occasionally succeeding while failing a million times along the way, they would become experts. With no human guidance.

The following years, DeepMind went ahead and beat increasingly complex games, utilizing novel reinforcement learning techniques to beat games that was previously thought to be extremely hard for computer to be good at because of their high complexity. 

While machines have been better than every living human at chess for about 20 years, they have struggled to beat humans at its Asian cousin Go. The amount of possible moves at each step is so high that it’s unfeasible for computers to play it in the same brute-forceish way that they have succeeded in chess
